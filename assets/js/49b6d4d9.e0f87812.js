"use strict";(globalThis.webpackChunkai_robotics_textbook=globalThis.webpackChunkai_robotics_textbook||[]).push([[7111],{8453:(e,n,i)=>{i.d(n,{R:()=>r,x:()=>a});var t=i(6540);const o={},s=t.createContext(o);function r(e){const n=t.useContext(s);return t.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:r(e.components),t.createElement(s.Provider,{value:n},e.children)}},9449:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>c,contentTitle:()=>a,default:()=>p,frontMatter:()=>r,metadata:()=>t,toc:()=>l});const t=JSON.parse('{"id":"module-3/computer-vision","title":"Computer Vision for Robotics","description":"Explore the fundamental concepts and practical applications of computer vision in robotics.","source":"@site/docs/module-3/13-computer-vision.md","sourceDirName":"module-3","slug":"/module-3/computer-vision","permalink":"/hackathon_spec_kit_book/docs/module-3/computer-vision","draft":false,"unlisted":false,"tags":[{"inline":true,"label":"computer vision","permalink":"/hackathon_spec_kit_book/docs/tags/computer-vision"},{"inline":true,"label":"robotics","permalink":"/hackathon_spec_kit_book/docs/tags/robotics"},{"inline":true,"label":"perception","permalink":"/hackathon_spec_kit_book/docs/tags/perception"},{"inline":true,"label":"python","permalink":"/hackathon_spec_kit_book/docs/tags/python"},{"inline":true,"label":"ros2","permalink":"/hackathon_spec_kit_book/docs/tags/ros-2"}],"version":"current","lastUpdatedAt":1765144290000,"sidebarPosition":13,"frontMatter":{"title":"Computer Vision for Robotics","slug":"computer-vision","sidebar_position":13,"description":"Explore the fundamental concepts and practical applications of computer vision in robotics.","tags":["computer vision","robotics","perception","python","ros2"]},"sidebar":"tutorialSidebar","previous":{"title":"Unity for Robotics Visualization & HRI","permalink":"/hackathon_spec_kit_book/docs/module-2/unity-robotics"},"next":{"title":"NVIDIA Isaac Sim: Set Up & Fundamentals","permalink":"/hackathon_spec_kit_book/docs/module-3/isaac-sim-fundamentals"}}');var o=i(4848),s=i(8453);const r={title:"Computer Vision for Robotics",slug:"computer-vision",sidebar_position:13,description:"Explore the fundamental concepts and practical applications of computer vision in robotics.",tags:["computer vision","robotics","perception","python","ros2"]},a=void 0,c={},l=[{value:"Summary",id:"summary",level:2},{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"Prerequisites",id:"prerequisites",level:2},{value:"Main Content",id:"main-content",level:2},{value:"Introduction to Computer Vision for Robotics",id:"introduction-to-computer-vision-for-robotics",level:3},{value:"The Role of Computer Vision in Robotics",id:"the-role-of-computer-vision-in-robotics",level:4},{value:"Fundamental Concepts in Computer Vision",id:"fundamental-concepts-in-computer-vision",level:3},{value:"Image Processing and Feature Extraction",id:"image-processing-and-feature-extraction",level:4},{value:"Object Detection and Recognition",id:"object-detection-and-recognition",level:4},{value:"Semantic Segmentation",id:"semantic-segmentation",level:4},{value:"3D Perception and Reconstruction",id:"3d-perception-and-reconstruction",level:4},{value:"Integrating Computer Vision in Robotic Systems",id:"integrating-computer-vision-in-robotic-systems",level:3},{value:"Enhancing Robotic Perception and Navigation with Computer Vision",id:"enhancing-robotic-perception-and-navigation-with-computer-vision",level:3},{value:"Visual SLAM",id:"visual-slam",level:4},{value:"Visual Servoing",id:"visual-servoing",level:4},{value:"Multi-Modal Perception",id:"multi-modal-perception",level:4},{value:"Key Takeaways",id:"key-takeaways",level:2},{value:"Glossary",id:"glossary",level:2},{value:"Review Questions",id:"review-questions",level:2}];function d(e){const n={admonition:"admonition",code:"code",h2:"h2",h3:"h3",h4:"h4",img:"img",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,s.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(n.h2,{id:"summary",children:"Summary"}),"\n",(0,o.jsx)(n.p,{children:"This chapter delves into the world of computer vision and its pivotal role in modern robotics. We will explore the core principles and techniques that enable robots to perceive and understand their visual environment, from object detection and recognition to semantic segmentation and 3D scene understanding. Through practical examples and case studies, we will demonstrate how computer vision can be seamlessly integrated into robotic systems to enhance their perception, navigation, and decision-making capabilities. By the end of this chapter, you will have a comprehensive understanding of the latest advancements in computer vision for robotics and be equipped with the knowledge to implement these techniques in your own projects."}),"\n",(0,o.jsx)(n.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,o.jsx)(n.p,{children:"By the end of this chapter, you will be able to:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Explain the fundamental concepts and algorithms in computer vision, including image processing, feature extraction, and object detection"}),"\n",(0,o.jsx)(n.li,{children:"Implement a ROS 2 node that performs object detection and recognition using a pre-trained deep learning model"}),"\n",(0,o.jsx)(n.li,{children:"Analyze the performance of a computer vision-based perception system and identify areas for improvement"}),"\n",(0,o.jsx)(n.li,{children:"Evaluate the role of computer vision in enhancing robotic navigation and control, such as visual SLAM and visual servoing"}),"\n",(0,o.jsx)(n.li,{children:"Create a multi-modal perception system that integrates computer vision with other sensor modalities (e.g., LiDAR, IMU) for robust and reliable robot perception"}),"\n"]}),"\n",(0,o.jsx)(n.h2,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Familiarity with Python programming and the ROS 2 framework"}),"\n",(0,o.jsx)(n.li,{children:"Basic understanding of machine learning and deep learning concepts"}),"\n",(0,o.jsx)(n.li,{children:"Knowledge of robot perception, navigation, and control principles"}),"\n"]}),"\n",(0,o.jsx)(n.h2,{id:"main-content",children:"Main Content"}),"\n",(0,o.jsx)(n.h3,{id:"introduction-to-computer-vision-for-robotics",children:"Introduction to Computer Vision for Robotics"}),"\n",(0,o.jsx)(n.p,{children:"Computer vision is a field of artificial intelligence that enables machines to interpret and understand visual information from the world around them. In the context of robotics, computer vision plays a crucial role in enabling robots to perceive their environment, detect and recognize objects, and make informed decisions based on visual cues."}),"\n",(0,o.jsx)(n.admonition,{type:"note",children:(0,o.jsx)(n.p,{children:"Computer vision is a fundamental component of many robotic systems, enabling them to perceive and interact with their surroundings in a more intelligent and autonomous manner."})}),"\n",(0,o.jsx)(n.h4,{id:"the-role-of-computer-vision-in-robotics",children:"The Role of Computer Vision in Robotics"}),"\n",(0,o.jsx)(n.p,{children:"Computer vision in robotics is used for a wide range of applications, including:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Object detection and recognition"}),"\n",(0,o.jsx)(n.li,{children:"Semantic segmentation and scene understanding"}),"\n",(0,o.jsx)(n.li,{children:"3D reconstruction and spatial awareness"}),"\n",(0,o.jsx)(n.li,{children:"Visual SLAM (Simultaneous Localization and Mapping)"}),"\n",(0,o.jsx)(n.li,{children:"Visual servoing and control"}),"\n"]}),"\n",(0,o.jsx)(n.p,{children:"These capabilities are essential for tasks such as navigation, manipulation, and interaction, allowing robots to navigate safely, interact with objects, and respond to their environment in real-time."}),"\n",(0,o.jsx)(n.h3,{id:"fundamental-concepts-in-computer-vision",children:"Fundamental Concepts in Computer Vision"}),"\n",(0,o.jsx)(n.p,{children:"To understand the integration of computer vision in robotics, we need to explore the core concepts and algorithms that underpin this field. Some of the key topics include:"}),"\n",(0,o.jsx)(n.h4,{id:"image-processing-and-feature-extraction",children:"Image Processing and Feature Extraction"}),"\n",(0,o.jsx)(n.p,{children:"Image processing techniques, such as filtering, edge detection, and color space transformations, are used to preprocess and enhance visual data. Feature extraction algorithms, like SIFT, SURF, and ORB, are then employed to identify and describe salient visual features in the image."}),"\n",(0,o.jsx)(n.h4,{id:"object-detection-and-recognition",children:"Object Detection and Recognition"}),"\n",(0,o.jsx)(n.p,{children:"Object detection algorithms, including classical methods like Viola-Jones and modern deep learning-based approaches like YOLO and Faster R-CNN, enable robots to locate and identify objects in their environment. Object recognition further classifies detected objects into semantic categories."}),"\n",(0,o.jsx)(n.h4,{id:"semantic-segmentation",children:"Semantic Segmentation"}),"\n",(0,o.jsx)(n.p,{children:"Semantic segmentation goes beyond object detection by labeling each pixel in an image with its corresponding semantic class, providing a detailed understanding of the scene."}),"\n",(0,o.jsx)(n.h4,{id:"3d-perception-and-reconstruction",children:"3D Perception and Reconstruction"}),"\n",(0,o.jsx)(n.p,{children:"Techniques like stereo vision, structured light, and RGB-D sensing can be used to obtain 3D information about the environment, enabling robots to build spatial awareness and perform tasks like obstacle avoidance and manipulation."}),"\n",(0,o.jsx)(n.h3,{id:"integrating-computer-vision-in-robotic-systems",children:"Integrating Computer Vision in Robotic Systems"}),"\n",(0,o.jsx)(n.p,{children:"To showcase the practical application of computer vision in robotics, let's explore a ROS 2 example that performs object detection and recognition."}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:"import rclpy\r\nfrom rclpy.node import Node\r\nfrom sensor_msgs.msg import Image\r\nfrom cv_bridge import CvBridge\r\nimport cv2\r\nimport torch\r\nfrom torchvision.models.detection import fasterrcnn_resnet50_fpn\r\n\r\nclass ObjectDetectionNode(Node):\r\n    def __init__(self):\r\n        super().__init__('object_detection_node')\r\n        self.subscriber = self.create_subscription(\r\n            Image, 'camera/image_raw', self.image_callback, 10)\r\n        self.bridge = CvBridge()\r\n        self.model = fasterrcnn_resnet50_fpn(pretrained=True).eval()\r\n\r\n    def image_callback(self, msg):\r\n        cv_image = self.bridge.imgmsg_to_cv2(msg, \"bgr8\")\r\n        boxes, labels, scores = self.detect_objects(cv_image)\r\n        # Visualize and publish the results\r\n        self.publish_detections(cv_image, boxes, labels, scores)\r\n\r\n    def detect_objects(self, image):\r\n        input_tensor = torch.from_numpy(image.transpose(2, 0, 1)).unsqueeze(0).float()\r\n        outputs = self.model(input_tensor)\r\n        boxes = outputs[0]['boxes'].detach().numpy()\r\n        labels = [self.model.COCO_INSTANCE_CATEGORY_NAMES[i] for i in outputs[0]['labels'].detach().numpy()]\r\n        scores = outputs[0]['scores'].detach().numpy()\r\n        return boxes, labels, scores\r\n\r\ndef main(args=None):\r\n    rclpy.init(args=args)\r\n    node = ObjectDetectionNode()\r\n    rclpy.spin(node)\r\n    rclpy.shutdown()\r\n\r\nif __name__ == '__main__':\r\n    main()\r\n\r\nIn this example, we create a ROS 2 node that subscribes to the `camera/image_raw` topic, performs object detection using a pre-trained Faster R-CNN model, and publishes the detected objects with their bounding boxes, labels, and confidence scores.\r\n\n"})}),"\n",(0,o.jsx)(n.admonition,{type:"tip",children:(0,o.jsx)(n.p,{children:"To integrate computer vision into your robotic system, you can leverage existing deep learning models or train custom models using frameworks like PyTorch or TensorFlow."})}),"\n",(0,o.jsx)(n.h3,{id:"enhancing-robotic-perception-and-navigation-with-computer-vision",children:"Enhancing Robotic Perception and Navigation with Computer Vision"}),"\n",(0,o.jsx)(n.p,{children:"Computer vision can significantly enhance a robot's perception and navigation capabilities. Some key applications include:"}),"\n",(0,o.jsx)(n.h4,{id:"visual-slam",children:"Visual SLAM"}),"\n",(0,o.jsx)(n.p,{children:"By combining computer vision techniques like feature extraction and visual odometry with other sensor data (e.g., IMU, wheel encoders), robots can perform Simultaneous Localization and Mapping (SLAM) to build a spatial representation of their environment and localize themselves within it."}),"\n",(0,o.jsx)(n.h4,{id:"visual-servoing",children:"Visual Servoing"}),"\n",(0,o.jsx)(n.p,{children:"Computer vision can be used for visual servoing, where a robot uses visual feedback to control its motion and interact with objects in its environment, enabling more precise and dexterous manipulation."}),"\n",(0,o.jsx)(n.h4,{id:"multi-modal-perception",children:"Multi-Modal Perception"}),"\n",(0,o.jsx)(n.p,{children:"Integrating computer vision with other sensor modalities, such as LiDAR and radar, can create a more robust and reliable perception system, allowing robots to make better decisions in complex environments."}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.img,{src:"https://mermaid.ink/img/pako:eNptjjEOwjAMRfeewlZCQkLcOgAj3aBWCQmkDhxAYkDcOABCXMEFOAAnYGLHjh3ZkSOCCNALAQqAQQgQwAQAjMKA-wZYAEBTwHKoRa2lU0J8t5wkEDTWnJzSdoHjSyJOjqYCUJJIxcRgSYOYMrAFMxIm-cWpZ3Lq6Ov_aTf8kLzRNhSqYs_PGbqRh7lRnKMi-gJjGbBh",alt:"Multimodal Perception System"})}),"\n",(0,o.jsx)(n.p,{children:"In this Mermaid diagram, we illustrate a multi-modal perception system that integrates computer vision with other sensor modalities, such as LiDAR and IMU, to provide a comprehensive understanding of the robot's environment."}),"\n",(0,o.jsx)(n.h2,{id:"key-takeaways",children:"Key Takeaways"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Computer vision is a crucial component of modern robotic systems, enabling them to perceive and interact with their environment in intelligent and autonomous ways."}),"\n",(0,o.jsx)(n.li,{children:"Core computer vision concepts, such as image processing, feature extraction, object detection, and semantic segmentation, are essential for robotic perception and decision-making."}),"\n",(0,o.jsx)(n.li,{children:"Integrating computer vision with other sensor modalities can create a more robust and reliable perception system for robots, enhancing their navigation, manipulation, and interaction capabilities."}),"\n",(0,o.jsx)(n.li,{children:"Practical ROS 2 examples demonstrate how to implement computer vision-based perception in real-world robotic applications."}),"\n"]}),"\n",(0,o.jsx)(n.h2,{id:"glossary",children:"Glossary"}),"\n",(0,o.jsxs)(n.ol,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Computer Vision"}),": The field of artificial intelligence that enables machines to interpret and understand visual information from the world around them."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Object Detection"}),": The process of locating and identifying objects in an image or video frame."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Semantic Segmentation"}),": The task of labeling each pixel in an image with its corresponding semantic class, providing a detailed understanding of the scene."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Visual SLAM"}),": Simultaneous Localization and Mapping (SLAM) using visual information, such as camera images, to build a spatial representation of the environment and localize the robot within it."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Visual Servoing"}),": The use of visual feedback to control the motion of a robot, enabling more precise and dexterous manipulation of objects."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Multi-Modal Perception"}),": The integration of multiple sensor modalities, such as computer vision, LiDAR, and IMU, to create a more robust and reliable perception system."]}),"\n"]}),"\n",(0,o.jsx)(n.h2,{id:"review-questions",children:"Review Questions"}),"\n",(0,o.jsxs)(n.ol,{children:["\n",(0,o.jsx)(n.li,{children:"Explain the role of computer vision in enhancing the perception and navigation capabilities of robotic systems."}),"\n",(0,o.jsx)(n.li,{children:"Implement a ROS 2 node that performs object detection using a pre-trained deep learning model, and describe how you would integrate it into a larger robotic system."}),"\n",(0,o.jsx)(n.li,{children:"Evaluate the benefits and challenges of using a multi-modal perception system that combines computer vision with other sensor modalities, such as LiDAR and IMU."}),"\n"]})]})}function p(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(d,{...e})}):d(e)}}}]);